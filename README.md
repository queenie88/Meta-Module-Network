# Meta-Module-Network
Code for WACV 2021 Paper "Meta Module Network for Compositional Visual Reasoning"
<p>
<img src="architecture.png" width="800">
</p>


## Meta-Function Definition
We define roughly 20+ functions based on the semantic-str provided in the original GQA dataset and categorize them into the following classes:
1. relate: finding objects with name and relation constraint, two version: normal + reverse.
2. filter: filter objects with given attributes or filter objects based on horizontal or vertical geometric position. 
3. filter_not: filter objects without given attributes
4. query: query object names or attributes or positions in the scene graph
5. verify: verify whether the objects contain certain attributes or their horizontal/vertial positions.
6. verify_rel: verify relations between different objects in the image.
7. choose: choose which attributes or names or geometric locations the current object has.
8. choose_rel: choose which relation the objects have.
9. and/or/exist: logical operations.
10: different: whether the objects are different
11: same: whether the objects are the same.
12: commmon: what attributes the objects have in common.
13: same_attr: whether the objects have the same given attributes.
14: different_attr: whether the objects have different given attributes.

## Data Downloading
Download all the question files and scene graph files and bottom-up features from the web server, it can take up to 300G disk space.
  ```
    bash get_data.sh
  ```
This script will download questions/ folder, and the "trainval_all_programs.json" is used for bootstrapping and "trainval_unbiased_programs.json" is used for finetunning in the paper. The "trainval_unbiased_programs.json" and "testdev_pred_programs.json" are both generated by the program generator model.

## Description of different files
- sceneGraphs/trainval_bounding_box.json: the scene graph provided by the original GQA dataset
  ```
    {
      imageId:
      {
        bouding_box_id:
        {
          x: number,
          y: number,
          w: number,
          h: number,
          relations: [{object: "bounding_box_id", name: "relation_name"} ... ],
          name: object_class,
          attributes: [attr1, attr2, ... ]
        },
        bouding_box_id:
        {
          ...
        },
      }
    }
  ```
- questions: the questions-program pairs and their associated images.
  ```
  [
    [
      "ImageId",
      "Question",
      "Programs": [f1, f2, ..., fn],
      "QuestionId",
      "Answer"
    ]
  ]
  ```

## Data Preprocessing [Optional]
If you want to know how the programs and training data are generated, please follow the following steps:

Download the questions from the original [GQA website](https://nlp.stanford.edu/data/gqa/questions1.2.zip) and then put it in the parent folder '../gqa-questions/', the following steps are aimed to convert "questions" into program format as follows:
1. preprocess the trainval_all_question into trainval_all_programs.json
  ```
    python preprocess.py trainval_all
  ```
2. preprocess the "balanced" programs into different forms:
  ```
    python preprocess.py create_balanced_programs
  ```
  
3. create the programs into the "input" forms for trainval_all_programs.json:
  ```
    python preprocess.py create_all_inputs
  ```

4. create the programs into the "input" forms for *balanced.json:
  ```
    python preprocess.py create_inputs
  ```

5. Preprocess "programs" into pair formats as follows:
  ```
    python generate_program.py --do_preprocess
  ```

## NL2Program Model:

- Train the sequence-2-sequence model:
  ```
    python generate_program.py --do_preprocess
  ```

- Evaluate the NL2Program
  ```
    python generate_program.py --do_testdev
  ```
  
- Prepare the generated programs for the modular transformer
  ```
    python generate_program.py --do_trainval_unbiased
  ```
  
## Meta Module Network
All the training data (under the questions/ folder) given to the networks are called '*_inputs.json', these files are simply a restructured data format (containing the dependency between the execution from different steps) from the original "*_programs.json" files. 

- *_programs.json
```
    "2354786",
    "Is the sky dark?",
    [
      "[2486325]=select(sky)",
      "?=verify([0], dark)"
    ],
    "02930152",
    "yes"
```
- *_inputs.json
```
    "2354786",
    "Is the sky dark?",
    [],
    [
      [
        "select",
        null,
        null,
        null,
        "sky",
        null,
        null,
        null
      ],
      [
        "verify",
        null,
        "dark",
        null,
        null,
        null,
        null,
        null
      ]
    ],
    [
      [], 
      [
        [
          1,
          0
        ]
      ]
    ],
    "02930152",
    "yes"
```

In the input file, the following data type is called program recipe, corresponding to "[2486325]=select(sky)".
```
[
  "select",
  null,
  null,
  null,
  "sky",
  null,
  null,
  null
],
```
In the input file, the following data type is called layer dependency. In the 0-th element (1st layer of MMN), there is only a [], which means nothing is dependent on the previous layer. In the 1-th element (2nd layer of MMN), there is a [1, 0], which means that the 1-st node's is dependent on 0-th node's output (e.g. "?=verify([0], dark)") in this layer. 
```
    [
      [], 
      [
        [
          1,
          0
        ]
      ]
    ],
```
The dependency relationship is the critical part in MMN, for example, the dependency of "[[], [[1,0], [3,0]], [[2,1]], [[4,2], [4,3]]]" is visualized as below: 
<p>
<img src="introduction.png" width="800">
</p>

## Training and Evaluation
- Prepare the inputs for the modular transformer:
  ```
    python preprocess.py create_pred_inputs
  ```
- Start the bootstrap training of the modular transoformer
  ```
   python run_experiments.py --do_train_all --model TreeSparsePostv2 --id TreeSparsePost2Full --stacking 2 --batch_size 1024
  ```
- Start the finetunning on the balanced split
  ```
    python run_experiments.py --do_finetune --id FinetuneTreeSparseStack2RemovalFullValSeed6999 --model TreeSparsePostv2 --load_from models/TreeSparsePost2Full --seed 6999 --stacking 2
  ```
- Test the model on the testdev split
  ```
    python run_experiments.py --do_testdev_pred --id FinetuneTreeSparseStack2RemovalValSeed6777 --load_from [MODEL_NAME]  --model TreeSparsePostv2 --stacking 2
  ```

## Citation
If you find this paper useful, please add the following reference to your paper.
```
  @article{chen2019meta,
  title={Meta module network for compositional visual reasoning},
  author={Chen, Wenhu and Gan, Zhe and Li, Linjie and Cheng, Yu and Wang, William and Liu, Jingjing},
  journal={Proceedings of WACV},
  year={2021}
}
```
